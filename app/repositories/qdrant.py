import sys
from pathlib import Path

from llama_index.core import Document, VectorStoreIndex
from llama_index.core.node_parser import HierarchicalNodeParser
from llama_index.readers.file import PDFReader

from app.core.config import settings
from app.core.database import ingestiers, retrievers
from app.core.logging import logger
from app.core.ml_models import embed_model
from app.utils.validators import ensure_path_exists


class IngestionPipeline:

    def load_pdf(self, file_path: Path | str) -> list[Document]:
        """–ó–∞–≥—Ä—É–∂–∞–µ–º PDF –ø–æ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É"""
        try:

            loc_dir = ensure_path_exists(file_path)
            logger.info(f"üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º PDF from: {loc_dir}")
            reader = PDFReader()
            documents = reader.load_data(file=loc_dir)
            logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∑–∏–ª–∏ {len(documents)} document(s) from PDF.")
            return documents

        except Exception as e:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")
            sys.exit(1)

    def chunk_documents(self, documents: list[Document]) -> list:
        """–†–∞–∑–±–∏–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–∞ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ —á–∞–Ω–∫–∏ (–Ω–æ–¥—ã)."""
        try:

            logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º —á–∞–Ω–∫–æ–≤–∞—Ç—å")
            node_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=[1024, 512])
            nodes = node_parser.get_nodes_from_documents(documents)
            logger.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(nodes)} –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏—Ö –Ω–æ–¥.")
            return nodes

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–±–∏–µ–Ω–∏–∏ –Ω–∞ —á–∞–Ω–∫–∏: {e}")
            sys.exit(1)

    def ingest_nodes_to_qdrant(self, nodes: list, collection_name: str):
        try:
            for i in range(len(settings.COLLECTIONS)):
                if collection_name == settings.COLLECTIONS[i]:
                    ingestier = ingestiers[i]
                    break

            logger.info(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å –≤ '{collection_name}' –≤ qdrant...")
            VectorStoreIndex(
                nodes=nodes,
                storage_context=ingestier,
                embed_model=embed_model,
                show_progress=True,
            )
            logger.info(
                f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–ø–∏—Å–∞–ª–∏ {len(nodes)} –≤ '{collection_name}' –≤ qdrant"
            )
        except Exception as e:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤ qdrant: {e}")

    def run(self, file_path: Path | str, collection_name: str):
        """
        –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: –∑–∞–≥—Ä—É–∑–∫–∞ PDF ‚Üí —á–∞–Ω–∫–∏–Ω–≥ ‚Üí –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤ Qdrant
        :param file_path: –ü—É—Ç—å –∫ PDF-—Ñ–∞–π–ª—É
        :param collection_name: –ò–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –≤ Qdrant
        """
        documents = self.load_pdf(file_path)
        nodes = self.chunk_documents(documents)
        self.ingest_nodes_to_qdrant(nodes, collection_name)


def retrieve_nodes_from_qdrant(query: str, collection_name: str):
    try:
        for i in range(len(settings.COLLECTIONS)):
            if collection_name == settings.COLLECTIONS[i]:
                retriever = retrievers[i]
                break

        logger.info(
            f'üîÑ –î–µ–ª–∞–µ–º retrieve –∑–∞–ø—Ä–æ—Å: "{query}" –∫ "{collection_name}" –≤ qdrant'
        )

        nodes = retriever.retrieve(query)
        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ–∫–ª–∏ {len(nodes)} –∏–∑ '{collection_name}' –≤ qdrant")
        return nodes
    except Exception as e:
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∏–∑ qdrant: {e}")
